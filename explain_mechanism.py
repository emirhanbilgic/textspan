"""
ğŸ“ CLIP Heatmap MekanizmasÄ± - GÃ¶rsel AÃ§Ä±klama
Bu script, kodun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ADIM ADIM gÃ¶sterir
"""

import numpy as np

print("="*80)
print("ğŸ§  CLIP HEATMAP MEKANÄZMASINI ANLAMAK")
print("="*80)

print("\n" + "â”€"*80)
print("ğŸ“¸ ADIM 1: GÃ–RÃœNTÃœ Ä°ÅLEME")
print("â”€"*80)

print("""
Bir kÃ¶pek resmi yÃ¼klÃ¼yoruz:
  ğŸ• dog.jpeg (original size: 1920Ã—1080)
  
Preprocessing:
  â†’ Resize: 224Ã—224
  â†’ Normalize: mean=[0.48145466, 0.4578275, 0.40821073]
  â†’ Tensor: shape [1, 3, 224, 224]
""")

print("\n" + "â”€"*80)
print("ğŸ”² ADIM 2: VISION TRANSFORMER (ViT) - PATCH'LERE BÃ–LME")
print("â”€"*80)

image_size = 224
patch_size = 14
num_patches = (image_size // patch_size) ** 2

print(f"""
ViT gÃ¶rÃ¼ntÃ¼yÃ¼ {patch_size}Ã—{patch_size} patch'lere bÃ¶ler:
  
  224Ã—224 gÃ¶rÃ¼ntÃ¼ â†’ {image_size // patch_size}Ã—{image_size // patch_size} grid = {num_patches} patches
  
GÃ¶rsel olarak:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚  â† 16 patches
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ ğŸ•ğŸ•ğŸ•ğŸ• â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚  â† KÃ¶pek burada!
  â”‚ â–¡ â–¡ â–¡ ğŸ•ğŸ•ğŸ•ğŸ•ğŸ•ğŸ• â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ ğŸ•ğŸ•ğŸ•ğŸ•ğŸ•ğŸ• â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ ğŸ•ğŸ•ğŸ•ğŸ• â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â”‚ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â–¡ â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
Her patch â†’ 1024 boyutlu embedding vector
+ 1 CLS token (class token) = 257 total tokens
""")

print("\n" + "â”€"*80)
print("ğŸ”— ADIM 3: MULTI-HEAD ATTENTION")
print("â”€"*80)

num_layers = 24
num_heads = 16
embed_dim = 1024

print(f"""
ViT-L-14 modeli:
  â€¢ {num_layers} Transformer layer
  â€¢ Her layer'da {num_heads} attention head
  â€¢ Embedding dimension: {embed_dim}
  
Attention nedir?
  â†’ Her patch diÄŸer patch'lerle "konuÅŸur"
  â†’ "Sen benimle ne kadar alakalÄ±sÄ±n?" diye sorar
  â†’ KÃ¶pek patch'leri birbirini "tanÄ±r", arka plan'Ä± ignore eder
  
Ã–rnek attention pattern (Layer 12, Head 3):
  
  Patch[64] (kÃ¶peÄŸin baÅŸÄ±):
    â”œâ”€ Patch[64] (kendisi)     â†’ 0.25 (yÃ¼ksek attention!)
    â”œâ”€ Patch[65] (kÃ¶pek gÃ¶vde)  â†’ 0.18 (yÃ¼ksek!)
    â”œâ”€ Patch[80] (kÃ¶pek bacak)  â†’ 0.12 (orta)
    â”œâ”€ Patch[10] (arka plan)    â†’ 0.01 (dÃ¼ÅŸÃ¼k!)
    â””â”€ Patch[15] (arka plan)    â†’ 0.01 (dÃ¼ÅŸÃ¼k!)
""")

# Simulate attention scores
print("\n" + "â”€"*80)
print("ğŸ“Š ADIM 4: ATTENTION TOPLAMA")
print("â”€"*80)

print("""
Kod:
  attentions[0, :, 1:, :].sum(axis=(0,2))
  
Ne yapÄ±yor?
  â€¢ [0] â†’ Batch'den ilk gÃ¶rÃ¼ntÃ¼
  â€¢ [:, 1:, :] â†’ CLS token'Ä± atla, sadece 256 image patch
  â€¢ .sum(axis=0) â†’ 24 layer'Ä± TOPLA
  â€¢ .sum(axis=2) â†’ 16 head'i TOPLA
  
SonuÃ§:
  [256 patches, 1024 dim] â†’ Her patch'in "toplam attention vektÃ¶rÃ¼"
  
Ã–rnek:
  Patch[64] â†’ [0.12, -0.05, 0.31, ..., 0.08]  (1024 sayÄ±)
  Patch[65] â†’ [0.15, -0.02, 0.28, ..., 0.11]
  ...
""")

print("\n" + "â”€"*80)
print("ğŸ’¬ ADIM 5: TEXT ENCODING")
print("â”€"*80)

prompts = [
    'a photo of a car',
    'a photo of a plane', 
    'a photo of a bird',
    'a photo of a cat',
    'a photo of a dog'
]

print(f"""
{len(prompts)} prompt'u encode ediyoruz:
""")

for i, prompt in enumerate(prompts, 1):
    print(f'  {i}. "{prompt}"')
    print(f'     â†’ Text Encoder â†’ [{embed_dim}d vector]')
    if i < len(prompts):
        print()

print("""
Text encoder Ã§Ä±ktÄ±sÄ±:
  shape: [5 prompts, 1024 dim]
  
  Normalize ediliyor (L2 norm = 1):
  embedding = embedding / ||embedding||
""")

print("\n" + "â”€"*80)
print("ğŸ¯ ADIM 6: BENZERLÄ°K HESAPLAMA (EN Ã–NEMLÄ°!)")
print("â”€"*80)

print("""
Kod:
  attention_map = attentions @ class_embedding.T
  
Matrix Ã§arpÄ±mÄ±:
  [256 patches, 1024 dim] @ [1024 dim, 5 prompts]
  = [256 patches, 5 prompts]
  
Bu NE DEMEK?
  â†’ Her patch iÃ§in, her prompt'la benzerlik skoru!
  
GÃ¶rsel Ã¶rnek (kÃ¶pek resmi iÃ§in):
""")

# Simulated similarity scores
dog_patches = [64, 65, 80, 81, 96, 97]
car_prompt_idx = 0
dog_prompt_idx = 4

print("""
                    car    plane   bird    cat     dog
                    â”€â”€â”€â”€   â”€â”€â”€â”€â”€   â”€â”€â”€â”€    â”€â”€â”€     â”€â”€â”€
  Patch[10] (bg)    0.12   0.08    0.11    0.09    0.10  â† Arka plan, hepsi dÃ¼ÅŸÃ¼k
  Patch[64] (ğŸ•)    0.15   0.11    0.18    0.45    0.78  â† KÃ¶pek! "dog" en yÃ¼ksek!
  Patch[65] (ğŸ•)    0.13   0.09    0.20    0.42    0.75  â† KÃ¶pek! "dog" yÃ¼ksek!
  Patch[80] (ğŸ•)    0.14   0.10    0.19    0.48    0.81  â† KÃ¶pek! "dog" en yÃ¼ksek!
  Patch[150](bg)    0.11   0.07    0.10    0.08    0.09  â† Arka plan
  
ğŸ” Dikkat: KÃ¶pek patch'leri "dog" prompt'u iÃ§in yÃ¼ksek skor alÄ±yor!
""")

print("\n" + "â”€"*80)
print("ğŸ“ ADIM 7: SPATIAL RESHAPE")
print("â”€"*80)

print("""
[256, 5] tensor'Ä± â†’ [16, 16, 5] grid'e reshape ediyoruz
Sonra bilinear interpolation ile 224Ã—224'e bÃ¼yÃ¼tÃ¼yoruz

  [256, 5]  â†’  reshape  â†’  [1, 5, 16, 16]  â†’  interpolate  â†’  [1, 5, 224, 224]
  
ArtÄ±k her piksel iÃ§in, her prompt'un skoru var!
""")

print("\n" + "â”€"*80)
print("ğŸ¨ ADIM 8: NORMALIZASYON VE GÃ–RSELLEÅTÄRME")
print("â”€"*80)

# Simulate scores
np.random.seed(42)
car_scores = np.random.uniform(0.1, 0.3, 256)
car_scores[50:70] = np.random.uniform(0.6, 0.9, 20)  # Araba bÃ¶lgesi (varsayÄ±msal)

dog_scores = np.random.uniform(0.1, 0.3, 256)
dog_scores[60:85] = np.random.uniform(0.7, 0.95, 25)  # KÃ¶pek bÃ¶lgesi

all_scores = np.stack([car_scores, dog_scores])
mean_scores = all_scores.mean(axis=0)

print("""
Ã–NEMLÄ°: Relative Normalization!

  relative_score[i] = score[i] - mean(all_scores)
  
Neden?
  â†’ Mutlak skor deÄŸil, ORTALAMAYA GÃ–RE fark Ã¶nemli!
  â†’ "Bu prompt iÃ§in model diÄŸerlerine GÃ–RE ne kadar fazla bakÄ±yor?"
  
Ã–rnek (Patch[64] - kÃ¶peÄŸin baÅŸÄ±):
""")

patch_idx = 64
print(f"""
  "a photo of a car"  â†’ score: 0.15 â†’ relative: 0.15 - 0.35 = -0.20 (MAVÄ°!)
  "a photo of a dog"  â†’ score: 0.78 â†’ relative: 0.78 - 0.35 = +0.43 (KIRMIZI!)
                                                              ^^^^^^^^
                                                              Ortalama: 0.35
""")

print("""
Min-Max normalization:
  normalized = (score - min) / (max - min)  â†’ [0, 1] aralÄ±ÄŸÄ±
  uint8 = normalized * 255                  â†’ [0, 255] aralÄ±ÄŸÄ±
  
Colormap (JET):
  0   â†’ ğŸ”µ MAVÄ°   (dÃ¼ÅŸÃ¼k attention)
  127 â†’ ğŸŸ¢ YEÅÄ°L  (orta)
  255 â†’ ğŸ”´ KIRMIZI (yÃ¼ksek attention)
""")

print("\n" + "â”€"*80)
print("ğŸ¤” PROMPT'LAR BÄ°RBÄ°RÄ°NÄ° ETKÄ°LÄ°YOR MU?")
print("â”€"*80)

print("""
CEVAP: KÄ±smen EVET!

1ï¸âƒ£ Model Inference SÄ±rasÄ±nda: HAYIR âŒ
   â€¢ Her prompt AYRI encode ediliyor
   â€¢ Model bir prompt'u iÅŸlerken diÄŸerlerinden habersiz
   â€¢ BaÄŸÄ±msÄ±z skorlar hesaplanÄ±yor

2ï¸âƒ£ GÃ¶rselleÅŸtirme SÄ±rasÄ±nda: EVET âœ…
   â€¢ Relative normalization kullanÄ±yoruz
   â€¢ Her prompt'un skoru, TÃœM prompt'larÄ±n ortalamasÄ±na gÃ¶re
   â€¢ Bu yÃ¼zden:
     - Bir prompt ekler/Ã§Ä±karÄ±rsanÄ±z â†’ Renkler DEÄÄ°ÅÄ°R
     - Ama model'in GERÃ‡EK skoru aynÄ± kalÄ±r
     
Ã–rnek:
  EÄŸer sadece "a photo of a dog" prompt'unu kullansaydÄ±k:
    â†’ KÃ¶pek bÃ¶lgesi yine yÃ¼ksek skor alÄ±rdÄ±
    â†’ Ama GÃ–RSELDE her yer orta-yÃ¼ksek renkte olurdu
    â†’ Ã‡Ã¼nkÃ¼ karÅŸÄ±laÅŸtÄ±racak baÅŸka prompt yok!
    
  5 prompt kullanÄ±nca:
    â†’ Her prompt diÄŸerleriyle KIYASLANIR
    â†’ "dog" prompt'u kÃ¶pek bÃ¶lgesinde DAHA FAZLA aktivasyon â†’ KIRMIZI
    â†’ "car" prompt'u kÃ¶pek bÃ¶lgesinde DAHA AZ aktivasyon â†’ MAVÄ°
""")

print("\n" + "â”€"*80)
print("ğŸ’¡ Ã–ZET")
print("â”€"*80)

print("""
Heatmap'ler ÅŸunu gÃ¶sterir:
  
  ğŸ”´ KIRMIZI = Model bu prompt iÃ§in bu bÃ¶lgeye ODAKLANMIÅ
  ğŸ”µ MAVÄ°   = Model bu prompt iÃ§in bu bÃ¶lgeyi YOK SAYMIÅ
  
NasÄ±l?
  1. GÃ¶rÃ¼ntÃ¼ â†’ 256 patch'e bÃ¶lÃ¼nÃ¼yor
  2. Her patch â†’ 24 layer Ã— 16 head attention geÃ§iyor
  3. Text prompt â†’ 1024d vektÃ¶r oluyor
  4. Her patch Ã— her prompt â†’ benzerlik skoru
  5. Ortalamaya gÃ¶re normalize â†’ relative attention
  6. Colormap â†’ gÃ¶rselleÅŸtirme
  
CLIP'in gÃ¼cÃ¼:
  â€¢ 400M gÃ¶rÃ¼ntÃ¼-text Ã§ifti ile eÄŸitilmiÅŸ
  â€¢ "KÃ¶pek" kelimesi â†’ kÃ¶pek gÃ¶rÃ¼ntÃ¼ feature'larÄ± ile align
  â€¢ Bu yÃ¼zden "a photo of a dog" prompt'u kÃ¶pek patch'lerini aktive ediyor!
""")

print("\n" + "="*80)
print("âœ… AÃ‡IKLAMA TAMAMLANDI!")
print("="*80)
print("\nDaha fazla detay iÃ§in: NASIL_CALISIR.md dosyasÄ±nÄ± oku!\n")

