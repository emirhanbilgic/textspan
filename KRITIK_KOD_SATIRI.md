# ğŸ”¥ EN KRÄ°TÄ°K KOD SATIRI - DETAYLI AÃ‡IKLAMA

## ğŸ“ Bu Tek SatÄ±r Her Åeyi YapÄ±yor!

```python
attention_map = attentions[0, :, 1:, :].sum(axis=(0,2)) @ class_embedding.T
```

Bu satÄ±r **heatmap'lerin Ã¶zÃ¼**! AdÄ±m adÄ±m parÃ§alayalÄ±m:

---

## ğŸ”¬ AdÄ±m AdÄ±m ParÃ§alama

### 1ï¸âƒ£ `attentions[0, :, 1:, :]`

**BaÅŸlangÄ±Ã§ Shape:** `attentions.shape = [1, 24, 257, 16, 1024]`

```
[1, 24, 257, 16, 1024]
 â”‚   â”‚   â”‚    â”‚   â””â”€â”€â”€ Embedding dimension (1024)
 â”‚   â”‚   â”‚    â””â”€â”€â”€â”€â”€â”€â”€ Attention heads (16)
 â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tokens: 1 CLS + 256 patches (257)
 â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Transformer layers (24)
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Batch size (1 gÃ¶rÃ¼ntÃ¼)
```

**Ä°ndeksleme:**
- `[0]` â†’ Ä°lk (ve tek) gÃ¶rÃ¼ntÃ¼yÃ¼ al
- `[:]` â†’ TÃ¼m 24 layer'Ä± al
- `[1:]` â†’ CLS token'Ä± atla (index 0), sadece 256 image patch'i al
- `[:]` â†’ TÃ¼m 16 head'i al

**SonuÃ§ Shape:** `[24, 256, 16, 1024]`

---

### 2ï¸âƒ£ `.sum(axis=(0,2))`

**Ã–nceki Shape:** `[24, 256, 16, 1024]`

```python
.sum(axis=(0,2))
      ^^^^^^
      axis=0: 24 layer'Ä± TOPLA
      axis=2: 16 head'i TOPLA
```

**Ne yapÄ±yor?**
- `axis=0` â†’ TÃ¼m layer'larÄ±n katkÄ±sÄ±nÄ± toplar (24 layer â†’ 1)
- `axis=2` â†’ TÃ¼m attention head'lerin katkÄ±sÄ±nÄ± toplar (16 head â†’ 1)

**GÃ¶rsel:**
```
         Layer 0    Layer 1    ...    Layer 23
         â”Œâ”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”
Head 0   â”‚ v1 â”‚    â”‚ v2 â”‚            â”‚v24 â”‚  â”
Head 1   â”‚ v1 â”‚    â”‚ v2 â”‚            â”‚v24 â”‚  â”‚
Head 2   â”‚ v1 â”‚    â”‚ v2 â”‚            â”‚v24 â”‚  â”‚
...      â”‚ .. â”‚    â”‚ .. â”‚            â”‚... â”‚  â”œâ”€ HEPSÄ°NÄ° TOPLA!
Head 15  â”‚ v1 â”‚    â”‚ v2 â”‚            â”‚v24 â”‚  â”‚
         â””â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”˜  â”˜
                        â†“
                   [1024d vektÃ¶r]
```

**SonuÃ§ Shape:** `[256, 1024]`

Yani: **Her patch iÃ§in 1024-boyutlu toplam attention vektÃ¶rÃ¼**

---

### 3ï¸âƒ£ `@ class_embedding.T`

**Matrix Multiplication (Dot Product)**

```
class_embedding.shape = [5, 1024]  (5 prompt, her biri 1024d)
class_embedding.T     = [1024, 5]  (transpose)
```

**Ã‡arpÄ±m:**
```
[256, 1024] @ [1024, 5] = [256, 5]
    â†‘            â†‘           â†‘   â†‘
  patches    dimensions   patches prompts
```

---

## ğŸ¯ Matrix Ã‡arpÄ±mÄ± Ne YapÄ±yor?

### Matematiksel AÃ§Ä±klama:

Patch `i` ve prompt `j` iÃ§in:

```
score[i, j] = Î£(attentions[i, k] Ã— class_embedding[j, k])
              k=0 to 1023
```

Bu **cosine similarity** hesabÄ±! (Ã§Ã¼nkÃ¼ vektÃ¶rler normalize edilmiÅŸ)

### GÃ¶rsel Ã–rnek:

```
Patch[64] (kÃ¶peÄŸin baÅŸÄ±):
  attention_vector = [0.12, -0.05, 0.31, 0.08, ..., 0.15]  (1024 sayÄ±)

Prompt "a photo of a dog":
  text_embedding   = [0.08,  0.02, 0.28, 0.11, ..., 0.19]  (1024 sayÄ±)

Dot Product:
  score = 0.12Ã—0.08 + (-0.05)Ã—0.02 + 0.31Ã—0.28 + ... + 0.15Ã—0.19
  score = 0.78  â† YÃœKSEK! KÃ¶pek patch'i "dog" prompt'uyla uyumlu!

Prompt "a photo of a car":
  text_embedding   = [-0.05, 0.15, -0.12, 0.03, ..., -0.08]

Dot Product:
  score = 0.12Ã—(-0.05) + (-0.05)Ã—0.15 + 0.31Ã—(-0.12) + ... 
  score = 0.15  â† DÃœÅÃœK! KÃ¶pek patch'i "car" prompt'uyla uyumsuz!
```

---

## ğŸŒˆ SonuÃ§: `[256, 5]` Tensor

```
                 "car"  "plane" "bird"  "cat"   "dog"
                 â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€
Patch[0]  (bg)   0.11    0.09    0.10    0.08    0.09
Patch[1]  (bg)   0.10    0.08    0.09    0.07    0.08
...
Patch[64] (ğŸ•)   0.15    0.11    0.18    0.45    0.78  â† KÃ¶pek!
Patch[65] (ğŸ•)   0.13    0.09    0.20    0.42    0.75
Patch[66] (ğŸ•)   0.14    0.10    0.19    0.48    0.81
...
Patch[255](bg)   0.09    0.07    0.08    0.06    0.07
```

**Her hÃ¼cre:** "Bu patch bu prompt'la ne kadar benzer?"

---

## ğŸ¨ GÃ¶rselleÅŸtirme AdÄ±mlarÄ±

### Reshape: `[256, 5]` â†’ `[16, 16, 5]`

```python
einops.rearrange(attention_map, '(B N M) C -> B C N M', N=16, M=16, B=1)
```

256 patch'i 16Ã—16 grid'e yerleÅŸtir:

```
                "dog" prompt iÃ§in:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 0.09 0.08 0.09 0.10 0.11 ... â”‚  â† Arka plan
â”‚ 0.08 0.07 0.08 0.09 0.10 ... â”‚
â”‚ 0.10 0.09 0.45 0.78 0.75 ... â”‚  â† KÃ¶pek baÅŸlÄ±yor!
â”‚ 0.11 0.10 0.81 0.79 0.82 ... â”‚  â† KÃ¶pek devam
â”‚ 0.09 0.08 0.48 0.75 0.73 ... â”‚
â”‚ 0.08 0.07 0.08 0.09 0.10 ... â”‚  â† Arka plan
â”‚ ...                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interpolate: `[16, 16, 5]` â†’ `[224, 224, 5]`

```python
F.interpolate(..., scale_factor=14, mode='bilinear')
```

16Ã—16 grid'i 224Ã—224'e bÃ¼yÃ¼t (smooth hale getir)

### Normalize ve Color:

```python
v = attention_map[idx] - np.mean(attention_map, axis=0)  # Relative
v_normalized = (v - v_min) / (v_max - v_min)           # [0, 1]
v_uint8 = np.uint8(v_normalized * 255)                  # [0, 255]
heatmap = cv2.applyColorMap(v_uint8, cv2.COLORMAP_JET)  # Color!
```

**Renk HaritasÄ± (JET):**
```
0   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”µ MAVÄ°
64  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸŸ¢ YEÅÄ°L
128 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸŸ¡ SARI
192 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸŸ  TURUNCU
255 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”´ KIRMIZI
```

---

## ğŸ’¡ Neden Bu Kadar Ä°yi Ã‡alÄ±ÅŸÄ±yor?

### CLIP'in EÄŸitimi:

1. **Contrastive Learning:**
   ```
   Pozitif Ã‡ift: (kÃ¶pek resmi, "a photo of a dog") â†’ YakÄ±n
   Negatif Ã‡ift: (kÃ¶pek resmi, "a photo of a car") â†’ Uzak
   ```

2. **400 Milyon Ã‡ift:**
   - Model milyonlarca gÃ¶rÃ¼ntÃ¼-text Ã§iftinden Ã¶ÄŸreniyor
   - "Dog" kelimesi â†’ kÃ¶pek visual feature'larÄ±yla align oluyor

3. **Attention Mechanism:**
   - Transformer her patch'in diÄŸerleriyle iliÅŸkisini Ã¶ÄŸreniyor
   - KÃ¶pek patch'leri birbirini "bulup" birlikte activate oluyor

### SonuÃ§:
```
"a photo of a dog" embed'i Ã— kÃ¶pek patch'leri = YÃœKSEK SKOR â†’ ğŸ”´
"a photo of a car" embed'i Ã— kÃ¶pek patch'leri = DÃœÅÃœK SKOR â†’ ğŸ”µ
```

---

## ğŸ”„ Ã–zet: Tek SatÄ±rda Neler Oluyor?

```python
attention_map = attentions[0, :, 1:, :].sum(axis=(0,2)) @ class_embedding.T
```

1. **`attentions[0, :, 1:, :]`** â†’ 256 patch, 24 layer, 16 head
2. **`.sum(axis=(0,2))`** â†’ Her patch iÃ§in toplam attention vektÃ¶rÃ¼
3. **`@ class_embedding.T`** â†’ Her patch Ã— her prompt benzerliÄŸi
4. **SonuÃ§:** `[256, 5]` â†’ Her patch'in her prompt'la skoru!

Bu skorlar â†’ reshape â†’ interpolate â†’ normalize â†’ colormap â†’ **ğŸ¨ HEATMAP!**

---

## ğŸ¯ En Ã–nemli Nokta: Absolute (BaÄŸÄ±msÄ±z) Normalization

```python
v = attention_map[idx]  # Her prompt baÄŸÄ±msÄ±z!
```

**Neden bÃ¶yle?**
- Her prompt **kendi iÃ§inde** normalize ediliyor
- "Bu prompt iÃ§in model bu bÃ¶lgeye ne kadar bakÄ±yor?" (mutlak)
- Her prompt diÄŸerlerinden baÄŸÄ±msÄ±z olarak gÃ¶steriliyor

**SonuÃ§:**
- ğŸ”´ KIRMIZI = Model bu prompt iÃ§in bu bÃ¶lgeye YÃœKSEK attention veriyor
- ğŸ”µ MAVÄ° = Model bu prompt iÃ§in bu bÃ¶lgeye DÃœÅÃœK attention veriyor
- Her prompt kendi hikayesini anlatÄ±yor!

---

## âœ… SonuÃ§

Bu tek satÄ±r, CLIP modelinin **gÃ¶rsel-dilsel alignment**'Ä±nÄ± kullanarak, her gÃ¶rÃ¼ntÃ¼ bÃ¶lgesinin her text prompt'uyla ne kadar uyumlu olduÄŸunu hesaplÄ±yor. 

**Bu yÃ¼zden:**
- KÃ¶pek resmine "a photo of a dog" dediÄŸimizde â†’ KÃ¶pek KIRMIZI ğŸ”´
- KÃ¶pek resmine "a photo of a car" dediÄŸimizde â†’ KÃ¶pek MAVÄ° ğŸ”µ

Model **doÄŸru bÃ¶lgeleri doÄŸru kelimelerle eÅŸleÅŸtiriyor!** ğŸ¯

