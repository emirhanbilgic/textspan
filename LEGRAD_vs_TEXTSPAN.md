# ğŸ”¬ LeGrad vs CLIP Text-Based Decomposition (TextSpan)

## ğŸ“š Genel BakÄ±ÅŸ

Her iki yÃ¶ntem de **Vision Transformer (ViT)** modellerinde **hangi gÃ¶rÃ¼ntÃ¼ bÃ¶lgelerinin Ã¶nemli** olduÄŸunu gÃ¶stermek iÃ§in attention map'leri kullanÄ±yor. **AMA** tamamen farklÄ± yaklaÅŸÄ±mlar!

---

## ğŸ†š Temel Fark

| Ã–zellik | **LeGrad** | **TextSpan (Bu Makale)** |
|---------|------------|--------------------------|
| **YÃ¶ntem** | Gradient-based | Forward-pass based |
| **Backpropagation** | âœ… Gerekli | âŒ Gerekli deÄŸil |
| **Text KullanÄ±mÄ±** | Sadece final skor iÃ§in | Attention'larla direkt align |
| **Hesaplama** | âˆ‡A (gradient) | A @ T (dot product) |
| **Interpreability** | "Hangi attention output'u etkiliyor?" | "Hangi attention text'le uyumlu?" |

---

## ğŸ“Š LeGrad NasÄ±l Ã‡alÄ±ÅŸÄ±yor?

### **AdÄ±m 1: Forward Pass**
```
Image â†’ ViT â†’ Prediction score s^l
```

### **AdÄ±m 2: Backward Pass (GRADIENT!)**
```
âˆ‡A^l = âˆ‚s/âˆ‚A^l  (Attention map'e gÃ¶re gradient)
```

**Ne yapÄ±yor?**
- Model'in final prediction'Ä±nÄ± (Ã¶rn: "dog" class skoru) maksimize etmek iÃ§in
- Attention map'in **hangi deÄŸerlerinin deÄŸiÅŸmesi gerektiÄŸini** hesaplÄ±yor
- Yani: "Bu attention deÄŸeri artarsa, dog skoru nasÄ±l deÄŸiÅŸir?"

### **AdÄ±m 3: ReLU + Average**
```
E^l(s) = (1/hÂ·n) Î£_h Î£_i (âˆ‡A^l_{h,i,.})^+
```

**Ne yapÄ±yor?**
- Negatif gradient'leri at (sadece pozitif etki)
- TÃ¼m head'ler ve patch'ler Ã¼zerinden average al

### **AdÄ±m 4: Multi-Layer Aggregation**
```
E = norm(reshape(1/L Î£_l E^l))
```

**SonuÃ§:** Final prediction'Ä± **en Ã§ok etkileyen** attention pattern'leri

---

## ğŸ¯ TextSpan (Bu Makale) NasÄ±l Ã‡alÄ±ÅŸÄ±yor?

### **AdÄ±m 1: Forward Pass (Attention Ã‡Ä±ktÄ±larÄ±)**
```
Image â†’ ViT â†’ Attention outputs A^l
Text  â†’ TextEncoder â†’ Text embedding T
```

### **AdÄ±m 2: Projected Residual Stream (PRS)**
```
attentions[l, n, h, d]  (her layer, patch, head iÃ§in)
```

**Ne yapÄ±yor?**
- Her attention head'in **output vektÃ¶rÃ¼nÃ¼** direkt alÄ±yor
- Gradient yok! Sadece forward pass Ã§Ä±ktÄ±larÄ±

### **AdÄ±m 3: Aggregation (Toplama)**
```
A_total = Î£_layers Î£_heads attentions[l, n, h, :]
         â†’ [256 patches, 1024 dim]
```

**Ne yapÄ±yor?**
- TÃ¼m layer'larÄ±n ve head'lerin katkÄ±sÄ±nÄ± toplayarak
- Her patch iÃ§in **toplam representation vektÃ¶rÃ¼** elde ediyor

### **AdÄ±m 4: Text Alignment (DOT PRODUCT)**
```
score[n, c] = A_total[n, :] @ T[c, :]
            = Î£_d (A[n,d] Ã— T[c,d])
```

**Ne yapÄ±yor?**
- Her patch'in vektÃ¶rÃ¼ ile text embedding'i arasÄ±nda **cosine similarity**
- "Bu patch'in representation'Ä± bu text prompt'uyla ne kadar benzer?"

### **AdÄ±m 5: Reshape + Normalize**
```
heatmap = reshape(score) â†’ [16, 16] â†’ [224, 224]
```

**SonuÃ§:** Her patch'in text prompt'uyla **ne kadar semantically aligned** olduÄŸu

---

## ğŸ” Kritik Farklar

### **1. Gradient vs Forward Pass**

#### LeGrad:
```python
# BACKWARD PASS gerekli!
prediction = model(image)
gradient = torch.autograd.grad(prediction, attention_maps)
heatmap = process(gradient)
```

**Soruyor:** "Model prediction'Ä±nÄ± deÄŸiÅŸtirmek iÃ§in attention'Ä± nasÄ±l deÄŸiÅŸtirmeli?"

#### TextSpan:
```python
# Sadece FORWARD PASS!
attentions = model.encode_image(image)  # Attention Ã§Ä±ktÄ±larÄ±nÄ± al
text_emb = model.encode_text(text)      # Text'i encode et
heatmap = attentions @ text_emb.T       # Dot product!
```

**Soruyor:** "Bu patch zaten bu text'le ne kadar uyumlu?"

---

### **2. Text'in RolÃ¼**

#### LeGrad:
- Text sadece **final classification** iÃ§in kullanÄ±lÄ±r
- "dog" class'Ä±nÄ±n gradient'ini hesapla
- Text embeddingi direkt kullanÄ±lmÄ±yor

#### TextSpan:
- Text **direkt attention'larla align** ediliyor
- Text embedding attention space'inde yaÅŸÄ±yor
- CLIP'in contrastive learning'inden faydalanÄ±yor

---

### **3. Interpreability**

#### LeGrad: **"Bu attention deÄŸeri prediction'Ä± ETKÄ°LÄ°YOR"**
```
YÃ¼ksek gradient â†’ Bu attention output'u deÄŸiÅŸirse, prediction Ã§ok deÄŸiÅŸir
DÃ¼ÅŸÃ¼k gradient  â†’ Bu attention output'u deÄŸiÅŸirse, prediction az deÄŸiÅŸir
```

**Analoji:** "Bu tuÄŸlayÄ± Ã§Ä±karÄ±rsam, bina ne kadar sallanÄ±r?"

#### TextSpan: **"Bu attention deÄŸeri text'le UYUMLU"**
```
YÃ¼ksek skor â†’ Bu patch'in representation'Ä± text embedding'e yakÄ±n
DÃ¼ÅŸÃ¼k skor  â†’ Bu patch'in representation'Ä± text embedding'den uzak
```

**Analoji:** "Bu tuÄŸla zaten istediÄŸim renkte mi?"

---

## ğŸ“ Matematiksel KarÅŸÄ±laÅŸtÄ±rma

### **LeGrad FormÃ¼lÃ¼:**
```
E^l(s) = (1/hÂ·n) Î£_h Î£_i (âˆ‚s/âˆ‚A^l_{h,i,.})^+
```

**Neler var:**
- `âˆ‚s/âˆ‚A` â†’ Gradient (backprop gerekli)
- `(.)^+` â†’ ReLU (negatif gradient'leri at)
- Average over heads and patches

### **TextSpan FormÃ¼lÃ¼:**
```
score[n, c] = (Î£_l Î£_h A^l_{n,h,:}) Â· T_c
```

**Neler var:**
- `A^l_{n,h,:}` â†’ Attention output (forward pass)
- `Â· T_c` â†’ Dot product with text
- Sum over layers and heads

---

## ğŸ¨ GÃ¶rselleÅŸtirme FarklarÄ±

### **LeGrad:**
```
KÃ¶pek resmi + "dog" class:
  â†’ Hangi bÃ¶lgeler "dog" skorunu EN Ã‡OK artÄ±rÄ±yor?
  â†’ KÃ¶peÄŸin ayÄ±rt edici Ã¶zellikleri: baÅŸ, kulaklar, burun
```

**Odak:** Discriminative features (ayÄ±rt edici)

### **TextSpan:**
```
KÃ¶pek resmi + "a photo of a dog" prompt:
  â†’ Hangi bÃ¶lgeler "dog" text embedding'iyle EN BENZER?
  â†’ KÃ¶peÄŸin tÃ¼m bÃ¶lgeleri: baÅŸ, gÃ¶vde, bacaklar, kuyruk
```

**Odak:** Semantic alignment (anlamsal uyum)

---

## ğŸ§ª Avantajlar ve Dezavantajlar

### **LeGrad**

#### âœ… Avantajlar:
- **Karar mekanizmasÄ±nÄ±** aÃ§Ä±klÄ±yor
- Model hangi feature'lara **karar verirken** bakÄ±yor?
- Class-specific (her class iÃ§in Ã¶zelleÅŸtirilmiÅŸ)

#### âŒ Dezavantajlar:
- Backpropagation gerekli (yavaÅŸ)
- Gradient hesabÄ± kararsÄ±z olabilir
- Text'i direkt kullanmÄ±yor

### **TextSpan**

#### âœ… Avantajlar:
- **Semantic understanding** gÃ¶steriyor
- Text-image alignment direkt Ã¶lÃ§Ã¼lÃ¼yor
- Gradient yok â†’ daha hÄ±zlÄ±, daha stabil
- CLIP'in zero-shot gÃ¼cÃ¼nden faydalanÄ±yor
- **AÃ§Ä±k-uÃ§lu text prompt'lar** kullanabilir

#### âŒ Dezavantajlar:
- Final prediction'dan baÄŸÄ±msÄ±z (model yanlÄ±ÅŸ tahmin etse bile)
- Discriminative deÄŸil, semantic
- CLIP'e Ã¶zel (baÅŸka modellerde direkt Ã§alÄ±ÅŸmaz)

---

## ğŸ¯ Ne Zaman Hangisi?

### **LeGrad Kullan:**
```
â“ "Model NEDEN bu karar verdi?"
â“ "Model hataysa, hangi bÃ¶lgeye yanlÄ±ÅŸ baktÄ±?"
â“ "Discriminative feature'lar neler?"
```

**Ã–rnek:** Medical imaging'de yanlÄ±ÅŸ tanÄ± analizi

### **TextSpan Kullan:**
```
â“ "Model bu kavramÄ± gÃ¶rÃ¼ntÃ¼de NEREDE gÃ¶rÃ¼yor?"
â“ "Text-image alignment nasÄ±l?"
â“ "Zero-shot olarak yeni kavramlarÄ± test etmek istiyorum"
```

**Ã–rnek:** "a dog with brown fur" vs "a dog with spots" gibi detaylÄ± prompt'larÄ± karÅŸÄ±laÅŸtÄ±rma

---

## ğŸ’¡ TextSpan'in AsÄ±l Ä°novasyonu

### **1. Attention Decomposition:**
Her layer ve head'in katkÄ±sÄ±nÄ± **ayrÄ± ayrÄ±** gÃ¶rebiliyoruz:
```python
attentions[layer=12, head=3] @ text  # Layer 12, Head 3'Ã¼n katkÄ±sÄ±
```

### **2. Text-Based Interpretation:**
Gradient yerine **semantic similarity** kullanÄ±yor:
```python
"a photo of a dog" â†’ kÃ¶pek bÃ¶lgeleri
"a photo of a golden retriever" â†’ sadece golden retriever Ã¶zellikleri
"a dog's tail" â†’ kuyruk
```

### **3. Zero-Shot Flexibility:**
Herhangi bir text prompt ile test edebilirsin:
```python
"a photo of a happy dog"
"a photo of a sad dog"
"a dog playing"
"a dog sleeping"
```

---

## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rmalÄ± Ã–rnek

**KÃ¶pek Resmi:**

### LeGrad Ã‡Ä±ktÄ±sÄ±:
```
Prompt: "dog" class
Heatmap: KÃ¶peÄŸin BAÅI Ã§ok kÄ±rmÄ±zÄ± (en discriminative)
         GÃ¶vde orta
         Bacaklar dÃ¼ÅŸÃ¼k
         Arka plan mavi
         
â†’ Model bu bÃ¶lgelere bakarak "dog" olduÄŸuna karar veriyor
```

### TextSpan Ã‡Ä±ktÄ±sÄ±:
```
Prompt: "a photo of a dog"
Heatmap: KÃ¶peÄŸin TÃœM BÃ–LÃœMÃœ kÄ±rmÄ±zÄ±/turuncu
         BaÅŸ, gÃ¶vde, bacaklar hepsi yÃ¼ksek
         Arka plan mavi
         
â†’ KÃ¶peÄŸin tÃ¼m bÃ¶lgeleri "dog" text embedding'iyle uyumlu
```

---

## ğŸ”¬ Kod KarÅŸÄ±laÅŸtÄ±rmasÄ±

### **LeGrad:**
```python
# Forward
prediction = model(image)
score = prediction[class_idx]  # "dog" class

# Backward
score.backward()  # GRADIENT!
gradients = attention_map.grad

# Process
heatmap = process_gradients(gradients)  # ReLU, average, etc.
```

### **TextSpan:**
```python
# Forward only
attentions = model.encode_image(image)  # [layers, patches, heads, dim]
text_emb = model.encode_text("a photo of a dog")  # [1024]

# Direct dot product
heatmap = attentions.sum(layers, heads) @ text_emb
# [256 patches, 1024] @ [1024] = [256]
```

---

## âœ… SonuÃ§

### **LeGrad:**
- **Gradient-based** attribution
- "Model decision'Ä±nÄ± etkileyen attention'lar"
- Backprop gerekli

### **TextSpan:**
- **Semantic alignment** based
- "Text ile uyumlu gÃ¶rsel bÃ¶lgeler"
- Forward pass only

### **Bu Makalenin AsÄ±l GÃ¼cÃ¼:**
CLIP'in **text-image alignment**'Ä±nÄ± kullanarak:
1. Gradient'e gerek kalmadan
2. Herhangi bir text prompt'la
3. Model'in gÃ¶rsel-semantik representation'Ä±nÄ± gÃ¶rebiliyoruz

**Ve en Ã¶nemlisi:** Her attention head ve layer'Ä±n ne yaptÄ±ÄŸÄ±nÄ± **text bazlÄ± olarak yorumlayabiliyoruz!**

---

## ğŸ“– Kaynaklar

- **LeGrad:** "LeGrad: Layer-wise Gradient-based Attribution for Vision Transformers"
- **TextSpan:** "Interpreting CLIP's Image Representation via Text-Based Decomposition" (Gandelsman et al., ICLR 2024)

